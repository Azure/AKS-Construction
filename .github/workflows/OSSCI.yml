name: InfraCI - OSS cluster

on:
  #Run on Manual execution
  workflow_dispatch:
    inputs:
      environment:
        description: 'Which GitHub Environment to deploy to'
        required: true
        default: "csu"
        type: environment

  #Run when PR's are made to main, where the changes are in the bicep directory or this workflow file itself
  pull_request:
    branches: [main]
    paths:
      - "bicep/*"
      - ".github/workflows/OSSCI.yml"

  #Run on a weekly schedule
  schedule:
    # At 9pm, every month.
    - cron: "0 21 1 1-12 *"
  
env:
  RG: "AksBicepAcc-Ci-OssCluster" #The resource group we're deploying to.
  RESNAME: "AksOss" #Used in Azure Resource Naming, overrides the default in the parameter file
  DEPNAME: "Dep${{ github.run_number }}" #Deployment Name
  AZCLIVERSION: 2.38.0 #Pinning to a specific AZ CLI version

permissions:
      id-token: write
      contents: read

jobs:
  ReusableWF:
    runs-on: ubuntu-latest
    environment:  ${{ github.event.inputs.Environment }}
    outputs:
      RG: ${{ env.RG }}
      ENVIRONMENT: ${{ github.event.inputs.Environment }}
      RESNAME: ${{ env.RESNAME }}
      PARAMFILE: ${{ env.ParamFilePath }}

    steps:
      - name: Dummy step
        run: echo "Resuable workflows can't be directly reference ENV/INPUTS (yet)"

  ContourDeploy:
    uses: ./.github/workflows/AKSC_Deploy.yml
    needs: [ReusableWF]
    with:
      environment: ${{ needs.ReusableWF.outputs.ENVIRONMENT }}
      rg: ${{ needs.ReusableWF.outputs.RG }}
      resourceName: azcontour
      templateParams: resourceName=az-contour agentCount=2 JustUseSystemPool=true custom_vnet=true enable_aad=true enableAzureRBAC=true adminPrincipalId=_USER_OBJECT_ID_ registries_sku=Standard acrPushRolePrincipalId=_USER_OBJECT_ID_ networkPolicy=azure azurepolicy=audit dnsZoneId=_BYODNSZONEID_ keyVaultAksCSI=true keyVaultCreate=true keyVaultOfficerRolePrincipalId=_USER_OBJECT_ID_
      postScriptParams: "ingress=contour,ingressEveryNode=true,dnsZoneId=_BYODNSZONEID_,certEmail=gdogg@microsoft.com,monitor=oss,enableMonitorIngress=true"
    secrets: 
      AZURE_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
      AZURE_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}
      AZURE_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
      USER_OBJECT_ID: ${{ secrets.USER_OBJECT_ID }}
      
  ContourDeploy_SmokeTest_SimpleApp:
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.environment }}
    needs: [ContourDeploy]
    steps:
      - uses: actions/checkout@v2

      - name: Azure Login
        uses: Azure/login@v1.4.3
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: AKS Connect
        env:
          AKSNAME: ${{ needs.ContourDeploy.outputs.AKSNAME}}
        run: az aks get-credentials -n $AKSNAME -g $RG --overwrite-existing

      - name: Kubelogin
        env:
          kubeloginversion: 'v0.0.13'
        run: |
          wget https://github.com/Azure/kubelogin/releases/download/${{ env.kubeloginversion }}/kubelogin-linux-amd64.zip
          unzip kubelogin-linux-amd64.zip
          sudo mv bin/linux_amd64/kubelogin /usr/bin
          kubelogin convert-kubeconfig -l azurecli

      - name: Deploy Simple Workload
        env:
          MANIFESTTESTURL: "https://raw.githubusercontent.com/Gordonby/AKS-K8S-Lab-L200/master/azure-vote-all-in-one-redis.yaml"
          NAMESP: "votey"
        run: |
            echo "Creating namespace $NAMESP"
            kubectl create namespace $NAMESP --dry-run=client -o yaml | kubectl apply -f -

            echo $MANIFESTTESTURL
            kubectl apply -f $MANIFESTTESTURL -n  $NAMESP

      - name: Verify Simple Workload
        id: simpleworkloadverify
        env:
          NAMESP: "votey"
        run: |
          sleep 2m #Give public ip a chance to be allocated

          kubectl get po -n  $NAMESP
          kubectl get svc -n  $NAMESP

          pubIp=$(kubectl get svc -n $NAMESP -o jsonpath='{.items[*].status.loadBalancer.ingress[0].ip}')
          echo $pubIp
          echo "::set-output name=SIMWORKLOADIP::$pubIp" #outputting for conditon

          curl $pubIp

  Cleanup:
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.environment }}
    needs: [ContourDeploy, ContourDeploy_SmokeTest_SimpleApp]
    if: github.event_name != 'workflow_dispatch'
    steps:
      - name: Azure Login
        uses: Azure/login@v1.4.3
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
          enable-AzPSSession: true

      - name: Install Pwsh modules
        shell: pwsh
        run: |
          Set-PSRepository -Name PSGallery -InstallationPolicy Trusted
          Install-Module -Name Az.Accounts
          Install-Module -Name Az.Resources

      - name: Cleanup
        shell: pwsh
        run: |
          $RG='${{ env.RG }}'

          # Get all ARM resources from all resource groups
          $rgToPurge = Get-AzResourceGroup -Name $RG
          try {
            #Remove all but public ip addresses
            Get-AzResource -ResourceGroupName $rgToPurge.ResourceGroupName | ? {$_.ResourceType -ne "Microsoft.Network/publicIPAddresses"} | Remove-AzResource -Force

            #Remove public ip addresses
            Get-AzResource -ResourceGroupName $rgToPurge.ResourceGroupName | ? {$_.ResourceType -eq "Microsoft.Network/publicIPAddresses"} | Remove-AzResource -Force

            #Final run to clean other dependant resources in parent-child graph
            Get-AzResource -ResourceGroupName $rgToPurge.ResourceGroupName | Remove-AzResource -Force
          }
          Catch #we're wanting to suppress failures in this step. If it fails to clean, the nightly automation will catch it.
          {
            write-output error
          }
